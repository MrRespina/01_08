{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b776570e-d290-4253-80d0-50bb11a5f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be79b4f-b243-49a0-9cbd-91620d83f574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습셋의 변형을 설정하는 부분\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,# 주어진 이미지의 크기를 설정\n",
    "                                   horizontal_flip=True, # 수평 대칭 이미지를 50% 확률로 만듬\n",
    "                                   width_shift_range=0.1, # 전체 크기의 15% 범위에서 좌우로 이동\n",
    "                                   height_shift_range=0.1, # 위, 아래로 이동\n",
    "                                   rotation_range=5, # 정해진 각도만큼 회전\n",
    "                                   shear_range=0.7, # 좌표 하나를 고정시키고 나머지를 이동\n",
    "                                   zoom_range=1.2, # 확대 또는 축소\n",
    "                                   vertical_flip=True, # 수직 대칭 이미지를 만듦\n",
    "                                   fill_mode='nearest' # 빈 공간을 채우는 방법, nearest : 비슷한 색으로                              \n",
    "                                  )   \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('./data/train', # 학습 셋이 있는 폴더 위치\n",
    "                                                    target_size = (150,150), # 사이즈 조절\n",
    "                                                    batch_size = 5,\n",
    "                                                    class_mode = 'binary'\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a12b01-ef82-4aa9-9764-758d0e7cb482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 셋 설정\n",
    "# 이미지를 부풀리지 않아도 됨.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)   \n",
    "\n",
    "test_generator = train_datagen.flow_from_directory('./data/test', # 학습 셋이 있는 폴더 위치\n",
    "                                                    target_size = (150,150), # 사이즈 조절\n",
    "                                                    batch_size = 5,\n",
    "                                                    class_mode = 'binary'\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7cd77d1-be67-4cf6-819f-fade2c34f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 만들어서 적용\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc7421e-5980-4373-88af-068b70ac787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "32/32 [==============================] - 5s 104ms/step - loss: 0.7753 - accuracy: 0.4750 - val_loss: 0.6927 - val_accuracy: 0.4800\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7049 - accuracy: 0.4938 - val_loss: 0.6982 - val_accuracy: 0.4400\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6882 - accuracy: 0.5562 - val_loss: 0.6897 - val_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.7017 - accuracy: 0.4812 - val_loss: 0.6907 - val_accuracy: 0.4800\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6946 - accuracy: 0.4750 - val_loss: 0.6872 - val_accuracy: 0.6400\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6908 - accuracy: 0.5125 - val_loss: 0.6876 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6881 - accuracy: 0.5250 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6963 - accuracy: 0.5437 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6854 - accuracy: 0.5312 - val_loss: 0.6881 - val_accuracy: 0.4400\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6767 - accuracy: 0.6000 - val_loss: 0.6781 - val_accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6883 - accuracy: 0.5750 - val_loss: 0.6801 - val_accuracy: 0.6400\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6800 - accuracy: 0.5312 - val_loss: 0.6692 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6781 - accuracy: 0.6125 - val_loss: 0.6642 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6765 - accuracy: 0.5688 - val_loss: 0.6643 - val_accuracy: 0.6200\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6696 - accuracy: 0.6062 - val_loss: 0.6654 - val_accuracy: 0.5800\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6426 - accuracy: 0.6187 - val_loss: 0.6217 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6345 - accuracy: 0.6500 - val_loss: 0.7241 - val_accuracy: 0.5200\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6479 - accuracy: 0.6687 - val_loss: 0.6449 - val_accuracy: 0.6200\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6025 - accuracy: 0.6875 - val_loss: 0.6089 - val_accuracy: 0.6800\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5982 - accuracy: 0.7188 - val_loss: 0.5629 - val_accuracy: 0.7800\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5918 - accuracy: 0.6750 - val_loss: 0.5509 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5717 - accuracy: 0.7312 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5548 - accuracy: 0.7437 - val_loss: 0.5287 - val_accuracy: 0.7800\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6134 - accuracy: 0.6500 - val_loss: 0.6031 - val_accuracy: 0.6200\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5888 - accuracy: 0.7625 - val_loss: 0.5486 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5564 - accuracy: 0.7188 - val_loss: 0.5077 - val_accuracy: 0.7400\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5365 - accuracy: 0.7312 - val_loss: 0.4894 - val_accuracy: 0.8200\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5162 - accuracy: 0.7312 - val_loss: 0.4335 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4822 - accuracy: 0.8125 - val_loss: 0.4371 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5291 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4559 - accuracy: 0.8125 - val_loss: 0.4849 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.3882 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4761 - accuracy: 0.7563 - val_loss: 0.4131 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4613 - accuracy: 0.7688 - val_loss: 0.3475 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4516 - accuracy: 0.8062 - val_loss: 0.2886 - val_accuracy: 0.9400\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4483 - accuracy: 0.7688 - val_loss: 0.5219 - val_accuracy: 0.7800\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4125 - accuracy: 0.7937 - val_loss: 0.4074 - val_accuracy: 0.8600\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4015 - accuracy: 0.8375 - val_loss: 0.4083 - val_accuracy: 0.7400\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.3851 - val_accuracy: 0.8400\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.4345 - accuracy: 0.7750 - val_loss: 0.3703 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(learning_rate=0.0002),metrics=['accuracy'])\n",
    "\n",
    "espc = EarlyStopping(monitor='val_loss',patience=5)\n",
    "\n",
    "his = model.fit(train_generator,epochs=100,validation_data=test_generator,validation_steps=10,callbacks=[espc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a504dc-230b-4e68-8b78-f2ded162173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input,models,layers,metrics,optimizers\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6994c1a4-0587-4f77-a1d0-ded5249c5f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 전이 학습\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,# 주어진 이미지의 크기를 설정\n",
    "                                   horizontal_flip = True, # 수평 대칭 이미지를 50% 확률로 만듬\n",
    "                                   width_shift_range = 0.1, # 전체 크기의 15% 범위에서 좌우로 이동\n",
    "                                   height_shift_range = 0.1, # 위, 아래로 이동\n",
    "                                   rotation_range = 5, # 정해진 각도만큼 회전\n",
    "                                   shear_range = 0.7, # 좌표 하나를 고정시키고 나머지를 이동\n",
    "                                   zoom_range = 1.2, # 확대 또는 축소\n",
    "                                   vertical_flip = True, # 수직 대칭 이미지를 만듦\n",
    "                                   fill_mode = 'nearest' # 빈 공간을 채우는 방법, nearest : 비슷한 색으로                              \n",
    "                                  )   \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('./data/train', # 학습 셋이 있는 폴더 위치\n",
    "                                                    target_size = (150,150), # 사이즈 조절\n",
    "                                                    batch_size = 5,\n",
    "                                                    class_mode = 'binary'\n",
    "                                                   )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)   \n",
    "\n",
    "test_generator = train_datagen.flow_from_directory('./data/test', # 학습 셋이 있는 폴더 위치\n",
    "                                                    target_size = (150,150), # 사이즈 조절\n",
    "                                                    batch_size = 5,\n",
    "                                                    class_mode = 'binary'\n",
    "                                                   )\n",
    "\n",
    "# VGG16 모델\n",
    "transfer_model = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))\n",
    "transfer_model.trainable = False\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb341d36-e1de-4404-9f77-07e75f7e14d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                524352    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15239105 (58.13 MB)\n",
      "Trainable params: 524417 (2.00 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 나의 모델 설정\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "\n",
    "finetune_model.add(Flatten())\n",
    "\n",
    "finetune_model.add(Dense(64))\n",
    "finetune_model.add(Activation('relu'))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Activation('relu'))\n",
    "\n",
    "finetune_model.add(Dense(1))\n",
    "finetune_model.add(Activation('sigmoid'))\n",
    "finetune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d14ab418-3789-4c08-b394-df2bf4fc6121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 9s 254ms/step - loss: 0.7156 - accuracy: 0.5188 - val_loss: 0.6522 - val_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.7096 - accuracy: 0.5312 - val_loss: 0.7673 - val_accuracy: 0.4200\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.7100 - accuracy: 0.5500 - val_loss: 0.6404 - val_accuracy: 0.6600\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.6415 - accuracy: 0.6125 - val_loss: 0.5929 - val_accuracy: 0.7200\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.7155 - accuracy: 0.5312 - val_loss: 0.6437 - val_accuracy: 0.7200\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.6533 - accuracy: 0.6125 - val_loss: 0.6392 - val_accuracy: 0.6800\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.6425 - accuracy: 0.6000 - val_loss: 0.6350 - val_accuracy: 0.6200\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.6576 - accuracy: 0.5625 - val_loss: 0.5896 - val_accuracy: 0.7400\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.6295 - accuracy: 0.5875 - val_loss: 0.6030 - val_accuracy: 0.6800\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.6088 - accuracy: 0.6438 - val_loss: 0.6294 - val_accuracy: 0.6400\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 0.6225 - accuracy: 0.6562 - val_loss: 0.5953 - val_accuracy: 0.6400\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.6447 - accuracy: 0.6375 - val_loss: 0.6069 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.6082 - accuracy: 0.6750 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5722 - accuracy: 0.6875 - val_loss: 0.5806 - val_accuracy: 0.6600\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.5913 - accuracy: 0.6812 - val_loss: 0.6096 - val_accuracy: 0.6200\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5976 - accuracy: 0.6562 - val_loss: 0.5635 - val_accuracy: 0.6400\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 0.5827 - accuracy: 0.7063 - val_loss: 0.5963 - val_accuracy: 0.6200\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5548 - accuracy: 0.7250 - val_loss: 0.5295 - val_accuracy: 0.7200\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.5602 - accuracy: 0.7000 - val_loss: 0.4745 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5442 - accuracy: 0.7000 - val_loss: 0.5347 - val_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.5330 - accuracy: 0.7125 - val_loss: 0.5500 - val_accuracy: 0.7400\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 0.4916 - accuracy: 0.7750 - val_loss: 0.5041 - val_accuracy: 0.7600\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 8s 259ms/step - loss: 0.5072 - accuracy: 0.7312 - val_loss: 0.4639 - val_accuracy: 0.7800\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 0.5533 - accuracy: 0.7312 - val_loss: 0.5342 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 0.5439 - accuracy: 0.7063 - val_loss: 0.5730 - val_accuracy: 0.6200\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.4954 - accuracy: 0.7250 - val_loss: 0.5353 - val_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5038 - accuracy: 0.7437 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.5040 - accuracy: 0.7625 - val_loss: 0.6052 - val_accuracy: 0.6800\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.5089 - accuracy: 0.7563 - val_loss: 0.4607 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 8s 251ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7200\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 0.4815 - accuracy: 0.7437 - val_loss: 0.4857 - val_accuracy: 0.7400\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.5573 - accuracy: 0.6625 - val_loss: 0.4453 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.4297 - accuracy: 0.8562 - val_loss: 0.5479 - val_accuracy: 0.7200\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.4732 - accuracy: 0.7312 - val_loss: 0.5141 - val_accuracy: 0.7400\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.5244 - accuracy: 0.6938 - val_loss: 0.4416 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.4992 - accuracy: 0.7625 - val_loss: 0.4257 - val_accuracy: 0.7600\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.4260 - accuracy: 0.8000 - val_loss: 0.4691 - val_accuracy: 0.7800\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 0.4723 - accuracy: 0.7500 - val_loss: 0.4072 - val_accuracy: 0.8400\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 0.4571 - accuracy: 0.7875 - val_loss: 0.4240 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.4857 - accuracy: 0.7875 - val_loss: 0.3812 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.4796 - accuracy: 0.7750 - val_loss: 0.4340 - val_accuracy: 0.7800\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.4824 - accuracy: 0.7375 - val_loss: 0.4030 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.4419 - accuracy: 0.8375 - val_loss: 0.4641 - val_accuracy: 0.7600\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.4151 - accuracy: 0.7937 - val_loss: 0.3308 - val_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.4086 - accuracy: 0.7812 - val_loss: 0.3055 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.4661 - accuracy: 0.7875 - val_loss: 0.3526 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.4318 - accuracy: 0.7750 - val_loss: 0.4350 - val_accuracy: 0.8200\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.4098 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.3974 - accuracy: 0.8125 - val_loss: 0.3229 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 8s 253ms/step - loss: 0.4134 - accuracy: 0.8250 - val_loss: 0.4183 - val_accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "finetune_model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(learning_rate=0.0002),metrics=['accuracy'])\n",
    "\n",
    "espc = EarlyStopping(monitor='val_loss',patience=5)\n",
    "\n",
    "his = finetune_model.fit(train_generator,epochs=100,validation_data=test_generator,validation_steps=10,callbacks=[espc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b01904-8d1d-4c0d-9564-9b02c44e4603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
